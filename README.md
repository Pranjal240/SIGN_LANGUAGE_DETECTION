# SIGN_LANGUAGE_DETECTION
# ğŸ¤Ÿ Sign Language Detection with Offline Voice Integration

This project is a real-time Sign Language Detection system that uses **MediaPipe**, **machine learning**, and an **offline text-to-speech (TTS) engine** to convert hand gestures into spoken words. Designed to be simple, editable, and powerful, it allows users to train, test, and expand the gesture recognition system without internet connectivity.

## ğŸ”§ Features

- ğŸ–ï¸ Real-time hand gesture detection using MediaPipe
- ğŸ§  Keypoint and pointer-based gesture classification
- ğŸ—£ï¸ Offline voice integration for speech output
- ğŸ“ Easy-to-edit CSV files for adding new data
- âŒ¨ï¸ Simple key controls:
  - `h` â€“ Hand-only detection
  - `k` â€“ Keypoint data recording
  - `n` â€“ Pointer history recording

## ğŸ§ª How It Works

1. **Detection** â€“ Uses your webcam to detect hand landmarks in real-time.
2. **Classification** â€“ Matches gestures to a trained dataset using keypoint history or pointer movement.
3. **Voice Output** â€“ Detected gesture is spoken aloud using an offline TTS engine.
4. **Customization** â€“ You can press keys to record new data and retrain the model easily.

## ğŸ—‚ï¸ Project Structure

